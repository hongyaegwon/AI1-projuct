{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeb3\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "File: train_emotion_classifier.py\n",
    "Author: Octavio Arriaga\n",
    "Email: arriaga.camargo@gmail.com\n",
    "Github: https://github.com/oarriaga\n",
    "Description: Train emotion classification model\n",
    "\"\"\"\n",
    "#위에 나온 깃허브를 참고\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from models.cnn import mini_XCEPTION\n",
    "from utils.datasets import DataManager\n",
    "from utils.datasets import split_data\n",
    "from utils.preprocessor import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '../trained_models/emotion_models/'\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: fer2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeb3\\AI project\\face_classification-master\\src\\utils\\datasets.py:71: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  emotions = pd.get_dummies(data['emotion']).as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "898/897 [==============================] - 38s 43ms/step - loss: 1.7442 - acc: 0.3411 - val_loss: 1.5618 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.56179, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.01-0.40.hdf5\n",
      "Epoch 2/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.4889 - acc: 0.4425 - val_loss: 1.4799 - val_acc: 0.4572\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.56179 to 1.47989, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.02-0.46.hdf5\n",
      "Epoch 3/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.3794 - acc: 0.4814 - val_loss: 1.3508 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.47989 to 1.35085, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.03-0.50.hdf5\n",
      "Epoch 4/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 1.3108 - acc: 0.5071 - val_loss: 1.5040 - val_acc: 0.4631\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.35085\n",
      "Epoch 5/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2651 - acc: 0.5225 - val_loss: 1.3169 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.35085 to 1.31690, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.05-0.52.hdf5\n",
      "Epoch 6/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2266 - acc: 0.5423 - val_loss: 1.2426 - val_acc: 0.5396\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.31690 to 1.24263, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.06-0.54.hdf5\n",
      "Epoch 7/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.2070 - acc: 0.5486 - val_loss: 1.2799 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24263\n",
      "Epoch 8/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1799 - acc: 0.5570 - val_loss: 1.1799 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.24263 to 1.17989, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.08-0.56.hdf5\n",
      "Epoch 9/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1646 - acc: 0.5631 - val_loss: 1.3293 - val_acc: 0.5241\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.17989\n",
      "Epoch 10/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1469 - acc: 0.5687 - val_loss: 1.2307 - val_acc: 0.5471\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.17989\n",
      "Epoch 11/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1249 - acc: 0.5760 - val_loss: 1.1908 - val_acc: 0.5548\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.17989\n",
      "Epoch 12/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1164 - acc: 0.5814 - val_loss: 1.1406 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.17989 to 1.14058, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.12-0.57.hdf5\n",
      "Epoch 13/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1079 - acc: 0.5847 - val_loss: 1.1706 - val_acc: 0.5665\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.14058\n",
      "Epoch 14/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0929 - acc: 0.5917 - val_loss: 1.1838 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.14058\n",
      "Epoch 15/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0820 - acc: 0.5967 - val_loss: 1.1832 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.14058\n",
      "Epoch 16/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0755 - acc: 0.5957 - val_loss: 1.1189 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.14058 to 1.11893, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.16-0.60.hdf5\n",
      "Epoch 17/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0655 - acc: 0.6015 - val_loss: 1.1229 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.11893\n",
      "Epoch 18/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0530 - acc: 0.6101 - val_loss: 1.1286 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.11893\n",
      "Epoch 19/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0506 - acc: 0.6073 - val_loss: 1.1037 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.11893 to 1.10373, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.19-0.59.hdf5\n",
      "Epoch 20/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0384 - acc: 0.6127 - val_loss: 1.1156 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.10373\n",
      "Epoch 21/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0344 - acc: 0.6146 - val_loss: 1.1378 - val_acc: 0.5828\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.10373\n",
      "Epoch 22/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 1.0243 - acc: 0.6161 - val_loss: 1.0874 - val_acc: 0.5971\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.10373 to 1.08745, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.22-0.60.hdf5\n",
      "Epoch 23/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0243 - acc: 0.6192 - val_loss: 1.0686 - val_acc: 0.6035\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.08745 to 1.06862, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.23-0.60.hdf5\n",
      "Epoch 24/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0175 - acc: 0.6203 - val_loss: 1.0700 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.06862\n",
      "Epoch 25/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.0105 - acc: 0.6252 - val_loss: 1.0870 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.06862\n",
      "Epoch 26/100\n",
      "898/897 [==============================] - 35s 40ms/step - loss: 1.0076 - acc: 0.6248 - val_loss: 1.1640 - val_acc: 0.5878\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.06862\n",
      "Epoch 27/100\n",
      "898/897 [==============================] - 35s 40ms/step - loss: 1.0024 - acc: 0.6260 - val_loss: 1.0776 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.06862\n",
      "Epoch 28/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0011 - acc: 0.6242 - val_loss: 1.0664 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.06862 to 1.06640, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.28-0.61.hdf5\n",
      "Epoch 29/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9940 - acc: 0.6332 - val_loss: 1.0884 - val_acc: 0.5918\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.06640\n",
      "Epoch 30/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9920 - acc: 0.6316 - val_loss: 1.0439 - val_acc: 0.6213\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.06640 to 1.04393, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.30-0.62.hdf5\n",
      "Epoch 31/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 0.9827 - acc: 0.6358 - val_loss: 1.0301 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.04393 to 1.03008, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.31-0.62.hdf5\n",
      "Epoch 32/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9788 - acc: 0.6333 - val_loss: 1.1253 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.03008\n",
      "Epoch 33/100\n",
      "898/897 [==============================] - 35s 40ms/step - loss: 0.9771 - acc: 0.6331 - val_loss: 1.1415 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.03008\n",
      "Epoch 34/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9725 - acc: 0.6379 - val_loss: 1.0920 - val_acc: 0.6103\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.03008\n",
      "Epoch 35/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9703 - acc: 0.6351 - val_loss: 1.0590 - val_acc: 0.6142\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.03008\n",
      "Epoch 36/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9669 - acc: 0.6437 - val_loss: 1.0960 - val_acc: 0.5999\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.03008\n",
      "Epoch 37/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9599 - acc: 0.6437 - val_loss: 1.0651 - val_acc: 0.6149\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.03008\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9509 - acc: 0.6455 - val_loss: 1.0688 - val_acc: 0.6158\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.03008\n",
      "Epoch 39/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9542 - acc: 0.6464 - val_loss: 1.0801 - val_acc: 0.6088\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.03008\n",
      "Epoch 40/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9546 - acc: 0.6464 - val_loss: 1.0382 - val_acc: 0.6180\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.03008\n",
      "Epoch 41/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.9476 - acc: 0.6472 - val_loss: 1.0684 - val_acc: 0.6063\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.03008\n",
      "Epoch 42/100\n",
      "898/897 [==============================] - 35s 40ms/step - loss: 0.9469 - acc: 0.6473 - val_loss: 1.0340 - val_acc: 0.6279\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.03008\n",
      "Epoch 43/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9453 - acc: 0.6484 - val_loss: 1.0280 - val_acc: 0.6218\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.03008 to 1.02801, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.43-0.62.hdf5\n",
      "Epoch 44/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.9361 - acc: 0.6523 - val_loss: 1.0207 - val_acc: 0.6287\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.02801 to 1.02070, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.44-0.63.hdf5\n",
      "Epoch 45/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9380 - acc: 0.6524 - val_loss: 1.0373 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.02070\n",
      "Epoch 46/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9336 - acc: 0.6532 - val_loss: 1.0183 - val_acc: 0.6319\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.02070 to 1.01827, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.46-0.63.hdf5\n",
      "Epoch 47/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.9308 - acc: 0.6524 - val_loss: 1.0477 - val_acc: 0.6179\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.01827\n",
      "Epoch 48/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9291 - acc: 0.6553 - val_loss: 1.0443 - val_acc: 0.6089\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.01827\n",
      "Epoch 49/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9252 - acc: 0.6548 - val_loss: 1.0460 - val_acc: 0.6218\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.01827\n",
      "Epoch 50/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9254 - acc: 0.6531 - val_loss: 1.0437 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.01827\n",
      "Epoch 51/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9244 - acc: 0.6577 - val_loss: 1.0690 - val_acc: 0.6148\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.01827\n",
      "Epoch 52/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.9135 - acc: 0.6622 - val_loss: 1.0316 - val_acc: 0.6251\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.01827\n",
      "Epoch 53/100\n",
      "898/897 [==============================] - 36s 41ms/step - loss: 0.9168 - acc: 0.6593 - val_loss: 1.0294 - val_acc: 0.6233\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.01827\n",
      "Epoch 54/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.9112 - acc: 0.6585 - val_loss: 1.0840 - val_acc: 0.6059\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.01827\n",
      "Epoch 55/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9078 - acc: 0.6630 - val_loss: 1.0254 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.01827\n",
      "Epoch 56/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.9061 - acc: 0.6642 - val_loss: 1.0627 - val_acc: 0.6133\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.01827\n",
      "Epoch 57/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.9056 - acc: 0.6639 - val_loss: 1.0680 - val_acc: 0.6134\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.01827\n",
      "Epoch 58/100\n",
      "898/897 [==============================] - 36s 41ms/step - loss: 0.9100 - acc: 0.6612 - val_loss: 1.0182 - val_acc: 0.6336\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.01827 to 1.01819, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.58-0.63.hdf5\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 59/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8558 - acc: 0.6822 - val_loss: 0.9765 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.01819 to 0.97650, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.59-0.65.hdf5\n",
      "Epoch 60/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.8390 - acc: 0.6898 - val_loss: 0.9709 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.97650 to 0.97094, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.60-0.65.hdf5\n",
      "Epoch 61/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8311 - acc: 0.6935 - val_loss: 0.9831 - val_acc: 0.6454\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.97094\n",
      "Epoch 62/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8302 - acc: 0.6941 - val_loss: 0.9723 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.97094\n",
      "Epoch 63/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.8293 - acc: 0.6950 - val_loss: 0.9768 - val_acc: 0.6473\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.97094\n",
      "Epoch 64/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8167 - acc: 0.6987 - val_loss: 0.9788 - val_acc: 0.6431\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.97094\n",
      "Epoch 65/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8165 - acc: 0.6992 - val_loss: 0.9732 - val_acc: 0.6457\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.97094\n",
      "Epoch 66/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8167 - acc: 0.6967 - val_loss: 0.9734 - val_acc: 0.6505\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.97094\n",
      "Epoch 67/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8156 - acc: 0.6979 - val_loss: 0.9694 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.97094 to 0.96940, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.67-0.65.hdf5\n",
      "Epoch 68/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8163 - acc: 0.6967 - val_loss: 0.9759 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.96940\n",
      "Epoch 69/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.8176 - acc: 0.6958 - val_loss: 0.9810 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.96940\n",
      "Epoch 70/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8130 - acc: 0.6999 - val_loss: 0.9718 - val_acc: 0.6534\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.96940\n",
      "Epoch 71/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.8111 - acc: 0.7000 - val_loss: 0.9752 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.96940\n",
      "Epoch 72/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 0.8086 - acc: 0.7003 - val_loss: 0.9756 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.96940\n",
      "Epoch 73/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8078 - acc: 0.7018 - val_loss: 0.9790 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.96940\n",
      "Epoch 74/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.8054 - acc: 0.7018 - val_loss: 0.9742 - val_acc: 0.6520\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.96940\n",
      "Epoch 75/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8036 - acc: 0.7046 - val_loss: 0.9844 - val_acc: 0.6520\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.96940\n",
      "Epoch 76/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8089 - acc: 0.7011 - val_loss: 0.9789 - val_acc: 0.6531\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.96940\n",
      "Epoch 77/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.8022 - acc: 0.7035 - val_loss: 0.9797 - val_acc: 0.6473\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.96940\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 36s 40ms/step - loss: 0.8022 - acc: 0.7034 - val_loss: 0.9806 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.96940\n",
      "Epoch 79/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 0.8024 - acc: 0.7035 - val_loss: 0.9790 - val_acc: 0.6502: 1s - loss\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.96940\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 80/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7978 - acc: 0.7070 - val_loss: 0.9773 - val_acc: 0.6499\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.96940\n",
      "Epoch 81/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 0.7917 - acc: 0.7084 - val_loss: 0.9765 - val_acc: 0.6505\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.96940\n",
      "Epoch 82/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.7980 - acc: 0.7059 - val_loss: 0.9770 - val_acc: 0.6527\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.96940\n",
      "Epoch 83/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7950 - acc: 0.7064 - val_loss: 0.9766 - val_acc: 0.6507\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.96940\n",
      "Epoch 84/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.7963 - acc: 0.7086 - val_loss: 0.9769 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.96940\n",
      "Epoch 85/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7963 - acc: 0.7049 - val_loss: 0.9781 - val_acc: 0.6519\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.96940\n",
      "Epoch 86/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.7902 - acc: 0.7076 - val_loss: 0.9768 - val_acc: 0.6519\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.96940\n",
      "Epoch 87/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7913 - acc: 0.7074 - val_loss: 0.9766 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.96940\n",
      "Epoch 88/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.7969 - acc: 0.7062 - val_loss: 0.9764 - val_acc: 0.6503\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.96940\n",
      "Epoch 89/100\n",
      "898/897 [==============================] - 387s 431ms/step - loss: 0.7956 - acc: 0.7071 - val_loss: 0.9763 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.96940\n",
      "Epoch 90/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.7900 - acc: 0.7107 - val_loss: 0.9772 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.96940\n",
      "Epoch 91/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 0.7877 - acc: 0.7096 - val_loss: 0.9779 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.96940\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 92/100\n",
      "898/897 [==============================] - 36s 41ms/step - loss: 0.7975 - acc: 0.7069 - val_loss: 0.9766 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.96940\n",
      "Epoch 93/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7896 - acc: 0.7082 - val_loss: 0.9770 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.96940\n",
      "Epoch 94/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7944 - acc: 0.7063 - val_loss: 0.9771 - val_acc: 0.6507\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.96940\n",
      "Epoch 95/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7922 - acc: 0.7121 - val_loss: 0.9763 - val_acc: 0.6503\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.96940\n",
      "Epoch 96/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7914 - acc: 0.7090 - val_loss: 0.9767 - val_acc: 0.6499\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.96940\n",
      "Epoch 97/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7916 - acc: 0.7081 - val_loss: 0.9764 - val_acc: 0.6510\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.96940\n",
      "Epoch 98/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 0.7934 - acc: 0.7086 - val_loss: 0.9762 - val_acc: 0.6505\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.96940\n",
      "Epoch 99/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7867 - acc: 0.7065 - val_loss: 0.9775 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.96940\n",
      "Epoch 100/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 0.7939 - acc: 0.7059 - val_loss: 0.9763 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.96940\n"
     ]
    }
   ],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(train_faces) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 62, 62, 8)    72          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 62, 62, 8)    32          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 62, 62, 8)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 60, 60, 8)    576         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 60, 60, 8)    32          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 60, 60, 8)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 60, 60, 16)   200         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 60, 60, 16)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 60, 60, 16)   400         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 30, 30, 16)   128         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 30, 30, 16)   64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_9[0][0]            \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 30, 30, 32)   656         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 30, 30, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 30, 30, 32)   1312        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 15, 15, 32)   512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 15, 15, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 15, 15, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 15, 15, 32)   0           max_pooling2d_10[0][0]           \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 15, 15, 64)   2336        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 15, 15, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 15, 15, 64)   4672        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     2048        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 64)     0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 8, 8, 128)    8768        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 8, 8, 128)    17536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 128)    8192        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 128)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 128)    512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 128)    0           max_pooling2d_12[0][0]           \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 7)      8071        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 7)            0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '../trained_models/emotion_models/'\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=15,\n",
    "                        width_shift_range=0.3,\n",
    "                        height_shift_range=0.3,\n",
    "                        zoom_range=.3,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: fer2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeb3\\AI project\\face_classification-master\\src\\utils\\datasets.py:71: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  emotions = pd.get_dummies(data['emotion']).as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "898/897 [==============================] - 110s 123ms/step - loss: 1.8745 - acc: 0.2569 - val_loss: 2.0331 - val_acc: 0.2708\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.03312, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.01-0.27.hdf5\n",
      "Epoch 2/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.6966 - acc: 0.3238 - val_loss: 1.6606 - val_acc: 0.3657\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.03312 to 1.66061, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.02-0.37.hdf5\n",
      "Epoch 3/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.5992 - acc: 0.3760 - val_loss: 1.5542 - val_acc: 0.4023\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.66061 to 1.55421, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.03-0.40.hdf5\n",
      "Epoch 4/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.5153 - acc: 0.4163 - val_loss: 1.3865 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.55421 to 1.38651, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.04-0.47.hdf5\n",
      "Epoch 5/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.4538 - acc: 0.4424 - val_loss: 1.3981 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.38651\n",
      "Epoch 6/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.4126 - acc: 0.4587 - val_loss: 1.4347 - val_acc: 0.4845\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.38651\n",
      "Epoch 7/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.3770 - acc: 0.4796 - val_loss: 1.4228 - val_acc: 0.4659\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.38651\n",
      "Epoch 8/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.3505 - acc: 0.4873 - val_loss: 1.2294 - val_acc: 0.5385\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.38651 to 1.22942, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.08-0.54.hdf5\n",
      "Epoch 9/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.3277 - acc: 0.4978 - val_loss: 1.3303 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.22942\n",
      "Epoch 10/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.3141 - acc: 0.4997 - val_loss: 1.2538 - val_acc: 0.5329\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.22942\n",
      "Epoch 11/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.3012 - acc: 0.5087 - val_loss: 1.2673 - val_acc: 0.5361\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.22942\n",
      "Epoch 12/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2859 - acc: 0.5180 - val_loss: 1.3014 - val_acc: 0.5394\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.22942\n",
      "Epoch 13/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2789 - acc: 0.5202 - val_loss: 1.2825 - val_acc: 0.5429\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.22942\n",
      "Epoch 14/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2658 - acc: 0.5205 - val_loss: 1.2029 - val_acc: 0.5561\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.22942 to 1.20293, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.14-0.56.hdf5\n",
      "Epoch 15/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2593 - acc: 0.5270 - val_loss: 1.1796 - val_acc: 0.5637\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.20293 to 1.17960, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.15-0.56.hdf5\n",
      "Epoch 16/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.2453 - acc: 0.5318 - val_loss: 1.1896 - val_acc: 0.5577\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.17960\n",
      "Epoch 17/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2356 - acc: 0.5358 - val_loss: 1.1412 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.17960 to 1.14117, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.17-0.58.hdf5\n",
      "Epoch 18/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.2258 - acc: 0.5391 - val_loss: 1.1612 - val_acc: 0.5708\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.14117\n",
      "Epoch 19/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2221 - acc: 0.5449 - val_loss: 1.1205 - val_acc: 0.5851\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.14117 to 1.12048, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.19-0.59.hdf5\n",
      "Epoch 20/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2192 - acc: 0.5439 - val_loss: 1.1460 - val_acc: 0.5815\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.12048\n",
      "Epoch 21/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.2141 - acc: 0.5445 - val_loss: 1.1568 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.12048\n",
      "Epoch 22/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.2106 - acc: 0.5444 - val_loss: 1.0965 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.12048 to 1.09651, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.22-0.60.hdf5\n",
      "Epoch 23/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1994 - acc: 0.5523 - val_loss: 1.1487 - val_acc: 0.5829\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.09651\n",
      "Epoch 24/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.2038 - acc: 0.5515 - val_loss: 1.1316 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.09651\n",
      "Epoch 25/100\n",
      "898/897 [==============================] - 35s 38ms/step - loss: 1.1876 - acc: 0.5537 - val_loss: 1.1003 - val_acc: 0.5945\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.09651\n",
      "Epoch 26/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1834 - acc: 0.5551 - val_loss: 1.0834 - val_acc: 0.6021\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.09651 to 1.08343, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.26-0.60.hdf5\n",
      "Epoch 27/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1798 - acc: 0.5567 - val_loss: 1.1188 - val_acc: 0.5907\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.08343\n",
      "Epoch 28/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1692 - acc: 0.5627 - val_loss: 1.3409 - val_acc: 0.5295\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.08343\n",
      "Epoch 29/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1674 - acc: 0.5627 - val_loss: 1.1072 - val_acc: 0.5950\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.08343\n",
      "Epoch 30/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1714 - acc: 0.5608 - val_loss: 1.1625 - val_acc: 0.5914\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.08343\n",
      "Epoch 31/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1740 - acc: 0.5584 - val_loss: 1.0892 - val_acc: 0.5986\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.08343\n",
      "Epoch 32/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1640 - acc: 0.5631 - val_loss: 1.1095 - val_acc: 0.6016\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.08343\n",
      "Epoch 33/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1627 - acc: 0.5659 - val_loss: 1.1353 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.08343\n",
      "Epoch 34/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1628 - acc: 0.5651 - val_loss: 1.1032 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.08343\n",
      "Epoch 35/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1522 - acc: 0.5693 - val_loss: 1.1373 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.08343\n",
      "Epoch 36/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1502 - acc: 0.5740 - val_loss: 1.0696 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.08343 to 1.06958, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.36-0.61.hdf5\n",
      "Epoch 37/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1492 - acc: 0.5701 - val_loss: 1.1357 - val_acc: 0.5837\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.06958\n",
      "Epoch 38/100\n",
      "898/897 [==============================] - 35s 39ms/step - loss: 1.1469 - acc: 0.5728 - val_loss: 1.0753 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.06958\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1455 - acc: 0.5701 - val_loss: 1.0790 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.06958\n",
      "Epoch 40/100\n",
      "898/897 [==============================] - 37s 42ms/step - loss: 1.1360 - acc: 0.5737 - val_loss: 1.0509 - val_acc: 0.6187\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.06958 to 1.05087, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.40-0.62.hdf5\n",
      "Epoch 41/100\n",
      "898/897 [==============================] - 36s 41ms/step - loss: 1.1407 - acc: 0.5752 - val_loss: 1.0955 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.05087\n",
      "Epoch 42/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1404 - acc: 0.5733 - val_loss: 1.0363 - val_acc: 0.6209\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.05087 to 1.03634, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.42-0.62.hdf5\n",
      "Epoch 43/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1301 - acc: 0.5774 - val_loss: 1.0528 - val_acc: 0.6155\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.03634\n",
      "Epoch 44/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1360 - acc: 0.5738 - val_loss: 1.0740 - val_acc: 0.6127\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.03634\n",
      "Epoch 45/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1288 - acc: 0.5776 - val_loss: 1.0897 - val_acc: 0.6021\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.03634\n",
      "Epoch 46/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1253 - acc: 0.5790 - val_loss: 1.0747 - val_acc: 0.6067\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.03634\n",
      "Epoch 47/100\n",
      "898/897 [==============================] - 36s 41ms/step - loss: 1.1231 - acc: 0.5795 - val_loss: 1.1016 - val_acc: 0.5993\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.03634\n",
      "Epoch 48/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.1232 - acc: 0.5827 - val_loss: 1.0818 - val_acc: 0.6073\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.03634\n",
      "Epoch 49/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1154 - acc: 0.5843 - val_loss: 1.1521 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.03634\n",
      "Epoch 50/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1147 - acc: 0.5816 - val_loss: 1.1059 - val_acc: 0.5995\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.03634\n",
      "Epoch 51/100\n",
      "898/897 [==============================] - 36s 41ms/step - loss: 1.1065 - acc: 0.5845 - val_loss: 1.0624 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.03634\n",
      "Epoch 52/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1158 - acc: 0.5831 - val_loss: 1.1601 - val_acc: 0.5907\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.03634\n",
      "Epoch 53/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1189 - acc: 0.5825 - val_loss: 1.0704 - val_acc: 0.6052\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.03634\n",
      "Epoch 54/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.1127 - acc: 0.5838 - val_loss: 1.0641 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.03634\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 55/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0702 - acc: 0.6004 - val_loss: 1.0107 - val_acc: 0.6317\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.03634 to 1.01066, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.55-0.63.hdf5\n",
      "Epoch 56/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0606 - acc: 0.6080 - val_loss: 1.0133 - val_acc: 0.6301\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.01066\n",
      "Epoch 57/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0510 - acc: 0.6100 - val_loss: 1.0054 - val_acc: 0.6357\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.01066 to 1.00539, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.57-0.64.hdf5\n",
      "Epoch 58/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0518 - acc: 0.6052 - val_loss: 1.0067 - val_acc: 0.6336\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.00539\n",
      "Epoch 59/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0520 - acc: 0.6103 - val_loss: 1.0050 - val_acc: 0.6346\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.00539 to 1.00496, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.59-0.63.hdf5\n",
      "Epoch 60/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0421 - acc: 0.6117 - val_loss: 1.0070 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.00496\n",
      "Epoch 61/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0475 - acc: 0.6088 - val_loss: 1.0017 - val_acc: 0.6353\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.00496 to 1.00170, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.61-0.64.hdf5\n",
      "Epoch 62/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0460 - acc: 0.6103 - val_loss: 1.0014 - val_acc: 0.6353\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.00170 to 1.00143, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.62-0.64.hdf5\n",
      "Epoch 63/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0397 - acc: 0.6099 - val_loss: 0.9951 - val_acc: 0.6414\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.00143 to 0.99509, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.63-0.64.hdf5\n",
      "Epoch 64/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0396 - acc: 0.6124 - val_loss: 1.0009 - val_acc: 0.6354\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.99509\n",
      "Epoch 65/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0374 - acc: 0.6130 - val_loss: 1.0009 - val_acc: 0.6390\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.99509\n",
      "Epoch 66/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0447 - acc: 0.6105 - val_loss: 0.9933 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.99509 to 0.99326, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.66-0.64.hdf5\n",
      "Epoch 67/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0376 - acc: 0.6112 - val_loss: 0.9947 - val_acc: 0.6432\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.99326\n",
      "Epoch 68/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0386 - acc: 0.6129 - val_loss: 1.0031 - val_acc: 0.6365\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.99326\n",
      "Epoch 69/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0345 - acc: 0.6147 - val_loss: 0.9926 - val_acc: 0.6403\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.99326 to 0.99260, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.69-0.64.hdf5\n",
      "Epoch 70/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0383 - acc: 0.6131 - val_loss: 0.9901 - val_acc: 0.6417\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.99260 to 0.99006, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.70-0.64.hdf5\n",
      "Epoch 71/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0299 - acc: 0.6175 - val_loss: 0.9991 - val_acc: 0.6374\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.99006\n",
      "Epoch 72/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0303 - acc: 0.6157 - val_loss: 1.0052 - val_acc: 0.6404\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.99006\n",
      "Epoch 73/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0284 - acc: 0.6165 - val_loss: 0.9989 - val_acc: 0.6339\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.99006\n",
      "Epoch 74/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0330 - acc: 0.6136 - val_loss: 1.0050 - val_acc: 0.6336\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.99006\n",
      "Epoch 75/100\n",
      "898/897 [==============================] - 36s 40ms/step - loss: 1.0298 - acc: 0.6146 - val_loss: 0.9907 - val_acc: 0.6406\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.99006\n",
      "Epoch 76/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.0286 - acc: 0.6160 - val_loss: 0.9851 - val_acc: 0.6402 - lo - ETA: 0s - loss: 1.0275 - acc: \n",
      "\n",
      "Epoch 00076: val_loss improved from 0.99006 to 0.98506, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.76-0.64.hdf5\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 37s 41ms/step - loss: 1.0319 - acc: 0.6105 - val_loss: 0.9895 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.98506\n",
      "Epoch 78/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0274 - acc: 0.6190 - val_loss: 0.9975 - val_acc: 0.6390\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.98506\n",
      "Epoch 79/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0346 - acc: 0.6128 - val_loss: 0.9924 - val_acc: 0.6385\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.98506\n",
      "Epoch 80/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0229 - acc: 0.6177 - val_loss: 0.9862 - val_acc: 0.6383\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.98506\n",
      "Epoch 81/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0278 - acc: 0.6157 - val_loss: 0.9898 - val_acc: 0.6411 1.0275 -\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.98506\n",
      "Epoch 82/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0235 - acc: 0.6188 - val_loss: 0.9965 - val_acc: 0.6397\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.98506\n",
      "Epoch 83/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0242 - acc: 0.6191 - val_loss: 0.9952 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.98506\n",
      "Epoch 84/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0299 - acc: 0.6163 - val_loss: 0.9886 - val_acc: 0.6441\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.98506\n",
      "Epoch 85/100\n",
      "898/897 [==============================] - 37s 42ms/step - loss: 1.0254 - acc: 0.6189 - val_loss: 0.9945 - val_acc: 0.6393\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.98506\n",
      "Epoch 86/100\n",
      "898/897 [==============================] - 37s 41ms/step - loss: 1.0287 - acc: 0.6191 - val_loss: 0.9878 - val_acc: 0.6378\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.98506\n",
      "Epoch 87/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0315 - acc: 0.6196 - val_loss: 0.9873 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.98506\n",
      "Epoch 88/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0246 - acc: 0.6172 - val_loss: 0.9896 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.98506\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 89/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0195 - acc: 0.6254 - val_loss: 0.9846 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.98506 to 0.98456, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.89-0.64.hdf5\n",
      "Epoch 90/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0174 - acc: 0.6214 - val_loss: 0.9831 - val_acc: 0.6424\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.98456 to 0.98315, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.90-0.64.hdf5\n",
      "Epoch 91/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0156 - acc: 0.6184 - val_loss: 0.9860 - val_acc: 0.6422\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.98315\n",
      "Epoch 92/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0142 - acc: 0.6227 - val_loss: 0.9842 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.98315\n",
      "Epoch 93/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0160 - acc: 0.6224 - val_loss: 0.9825 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.98315 to 0.98251, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.93-0.64.hdf5\n",
      "Epoch 94/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0129 - acc: 0.6207 - val_loss: 0.9856 - val_acc: 0.6428\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.98251\n",
      "Epoch 95/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0162 - acc: 0.6211 - val_loss: 0.9847 - val_acc: 0.6425\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.98251\n",
      "Epoch 96/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0181 - acc: 0.6215 - val_loss: 0.9841 - val_acc: 0.6414\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.98251\n",
      "Epoch 97/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0134 - acc: 0.6195 - val_loss: 0.9847 - val_acc: 0.6441\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.98251\n",
      "Epoch 98/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0197 - acc: 0.6209 - val_loss: 0.9858 - val_acc: 0.6422\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.98251\n",
      "Epoch 99/100\n",
      "898/897 [==============================] - 37s 42ms/step - loss: 1.0183 - acc: 0.6207 - val_loss: 0.9851 - val_acc: 0.6421\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.98251\n",
      "Epoch 100/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.0233 - acc: 0.6206 - val_loss: 0.9829 - val_acc: 0.6424\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.98251\n"
     ]
    }
   ],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(train_faces) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 62, 62, 8)    72          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 62, 62, 8)    32          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 62, 62, 8)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 60, 60, 8)    576         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 60, 60, 8)    32          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 60, 60, 8)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 60, 60, 16)   200         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 60, 60, 16)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 60, 60, 16)   400         activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 30, 30, 16)   128         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 30, 30, 16)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 30, 30, 16)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 30, 30, 16)   0           max_pooling2d_13[0][0]           \n",
      "                                                                 batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 30, 30, 32)   656         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 30, 30, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 30, 30, 32)   1312        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 32)   512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 15, 15, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 15, 15, 32)   128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 15, 15, 32)   0           max_pooling2d_14[0][0]           \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 15, 15, 64)   2336        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 15, 15, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 15, 15, 64)   4672        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 64)     2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 64)     0           max_pooling2d_15[0][0]           \n",
      "                                                                 batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 8, 8, 128)    8768        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 8, 8, 128)    17536       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 128)    8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 4, 4, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 128)    512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 128)    0           max_pooling2d_16[0][0]           \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 7)      8071        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 7)            0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '../trained_models/emotion_models/'\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=20,\n",
    "                        width_shift_range=0.5,\n",
    "                        height_shift_range=0.5,\n",
    "                        zoom_range=.5,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: fer2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeb3\\AI project\\face_classification-master\\src\\utils\\datasets.py:71: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  emotions = pd.get_dummies(data['emotion']).as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.9191 - acc: 0.2327 - val_loss: 1.8856 - val_acc: 0.2487\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.88563, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.01-0.25.hdf5\n",
      "Epoch 2/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.8232 - acc: 0.2564 - val_loss: 1.9614 - val_acc: 0.2588\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.88563\n",
      "Epoch 3/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.7830 - acc: 0.2712 - val_loss: 1.7447 - val_acc: 0.3157\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.88563 to 1.74473, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.03-0.32.hdf5\n",
      "Epoch 4/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.7500 - acc: 0.2891 - val_loss: 1.8599 - val_acc: 0.2880\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.74473\n",
      "Epoch 5/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.7191 - acc: 0.3054 - val_loss: 1.6038 - val_acc: 0.3841\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.74473 to 1.60383, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.05-0.38.hdf5\n",
      "Epoch 6/100\n",
      "898/897 [==============================] - 40s 44ms/step - loss: 1.6802 - acc: 0.3284 - val_loss: 1.5766 - val_acc: 0.4218\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60383 to 1.57657, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.06-0.42.hdf5\n",
      "Epoch 7/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.6495 - acc: 0.3406 - val_loss: 1.6215 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.57657\n",
      "Epoch 8/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.6269 - acc: 0.3536 - val_loss: 1.4830 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.57657 to 1.48302, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.08-0.44.hdf5\n",
      "Epoch 9/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5981 - acc: 0.3675 - val_loss: 1.3727 - val_acc: 0.4876\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.48302 to 1.37269, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.09-0.49.hdf5\n",
      "Epoch 10/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5818 - acc: 0.3810 - val_loss: 1.6404 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.37269\n",
      "Epoch 11/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5700 - acc: 0.3862 - val_loss: 1.6185 - val_acc: 0.4372\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.37269\n",
      "Epoch 12/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5511 - acc: 0.3927 - val_loss: 1.3722 - val_acc: 0.5011\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.37269 to 1.37217, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.12-0.50.hdf5\n",
      "Epoch 13/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5349 - acc: 0.4029 - val_loss: 1.4713 - val_acc: 0.4855\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.37217\n",
      "Epoch 14/100\n",
      "898/897 [==============================] - 40s 44ms/step - loss: 1.5256 - acc: 0.4076 - val_loss: 1.4738 - val_acc: 0.4890\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.37217\n",
      "Epoch 15/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5237 - acc: 0.4080 - val_loss: 1.2573 - val_acc: 0.5258\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.37217 to 1.25730, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.15-0.53.hdf5\n",
      "Epoch 16/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5152 - acc: 0.4098 - val_loss: 1.4974 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.25730\n",
      "Epoch 17/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.5060 - acc: 0.4154 - val_loss: 1.2866 - val_acc: 0.5124\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.25730\n",
      "Epoch 18/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.4936 - acc: 0.4194 - val_loss: 1.3623 - val_acc: 0.5008\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.25730\n",
      "Epoch 19/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4823 - acc: 0.4239 - val_loss: 1.3620 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.25730\n",
      "Epoch 20/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.4770 - acc: 0.4253 - val_loss: 1.3741 - val_acc: 0.5178\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.25730\n",
      "Epoch 21/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.4808 - acc: 0.4285 - val_loss: 1.2672 - val_acc: 0.5376\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.25730\n",
      "Epoch 22/100\n",
      "898/897 [==============================] - 38s 42ms/step - loss: 1.4750 - acc: 0.4279 - val_loss: 1.2882 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.25730\n",
      "Epoch 23/100\n",
      "898/897 [==============================] - 39s 44ms/step - loss: 1.4689 - acc: 0.4269 - val_loss: 1.4501 - val_acc: 0.5032\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.25730\n",
      "Epoch 24/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.4573 - acc: 0.4389 - val_loss: 1.3194 - val_acc: 0.51101s - los\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.25730\n",
      "Epoch 25/100\n",
      "898/897 [==============================] - 40s 45ms/step - loss: 1.4533 - acc: 0.4401 - val_loss: 1.2030 - val_acc: 0.5577\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.25730 to 1.20302, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.25-0.56.hdf5\n",
      "Epoch 26/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4582 - acc: 0.4365 - val_loss: 1.2588 - val_acc: 0.54758s - loss: 1.4564 - acc: 0.435 - ETA: 8s - l - ETA: 6s - loss: 1 - ETA: 5s - loss: 1.4573 - acc - ETA:\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.20302\n",
      "Epoch 27/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4372 - acc: 0.4463 - val_loss: 1.3476 - val_acc: 0.5329\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.20302\n",
      "Epoch 28/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4455 - acc: 0.4434 - val_loss: 1.2172 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.20302\n",
      "Epoch 29/100\n",
      "898/897 [==============================] - 41s 45ms/step - loss: 1.4396 - acc: 0.4434 - val_loss: 1.2414 - val_acc: 0.5577\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.20302\n",
      "Epoch 30/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4341 - acc: 0.4465 - val_loss: 1.1883 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.20302 to 1.18829, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.30-0.56.hdf5\n",
      "Epoch 31/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4336 - acc: 0.4485 - val_loss: 1.4153 - val_acc: 0.5348\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.18829\n",
      "Epoch 32/100\n",
      "898/897 [==============================] - 42s 46ms/step - loss: 1.4200 - acc: 0.4548 - val_loss: 1.3440 - val_acc: 0.5369\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.18829\n",
      "Epoch 33/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4274 - acc: 0.4502 - val_loss: 1.1813 - val_acc: 0.5709\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.18829 to 1.18129, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.33-0.57.hdf5\n",
      "Epoch 34/100\n",
      "898/897 [==============================] - 41s 45ms/step - loss: 1.4163 - acc: 0.4502 - val_loss: 1.3780 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18129\n",
      "Epoch 35/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4097 - acc: 0.4619 - val_loss: 1.1827 - val_acc: 0.5691\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.18129\n",
      "Epoch 36/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4136 - acc: 0.4536 - val_loss: 1.3642 - val_acc: 0.5096\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.18129\n",
      "Epoch 37/100\n",
      "898/897 [==============================] - 41s 46ms/step - loss: 1.4081 - acc: 0.4566 - val_loss: 1.2006 - val_acc: 0.5662\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.18129\n",
      "Epoch 38/100\n",
      "898/897 [==============================] - 43s 47ms/step - loss: 1.4025 - acc: 0.4588 - val_loss: 1.1636 - val_acc: 0.5701\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.18129 to 1.16356, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.38-0.57.hdf5\n",
      "Epoch 39/100\n",
      "898/897 [==============================] - 43s 47ms/step - loss: 1.4089 - acc: 0.4584 - val_loss: 1.2120 - val_acc: 0.5642\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.16356\n",
      "Epoch 40/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.4060 - acc: 0.4604 - val_loss: 1.2206 - val_acc: 0.5639\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.16356\n",
      "Epoch 41/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.3994 - acc: 0.4630 - val_loss: 1.1968 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.16356\n",
      "Epoch 42/100\n",
      "898/897 [==============================] - 41s 45ms/step - loss: 1.3990 - acc: 0.4659 - val_loss: 1.2294 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.16356\n",
      "Epoch 43/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.3913 - acc: 0.4661 - val_loss: 1.2197 - val_acc: 0.5690 ETA: 4s - lo\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.16356\n",
      "Epoch 44/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3893 - acc: 0.4652 - val_loss: 1.3461 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.16356\n",
      "Epoch 45/100\n",
      "898/897 [==============================] - 43s 47ms/step - loss: 1.3866 - acc: 0.4675 - val_loss: 1.2088 - val_acc: 0.5591\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.16356\n",
      "Epoch 46/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.3921 - acc: 0.4653 - val_loss: 1.1819 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.16356\n",
      "Epoch 47/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.3878 - acc: 0.4697 - val_loss: 1.2817 - val_acc: 0.5535 4s - loss: -  - ETA: 0s - loss: 1.3869 - acc: 0.4 - ETA: 0s - loss: 1.3873 - acc: 0.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.16356\n",
      "Epoch 48/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3863 - acc: 0.4697 - val_loss: 1.3696 - val_acc: 0.5339 ETA: 1s -  - ETA: 0s - loss: 1.3863 - acc: 0.469 - ETA: 0s - loss: 1.3862 - acc: 0.4\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.16356\n",
      "Epoch 49/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3859 - acc: 0.4667 - val_loss: 1.2193 - val_acc: 0.5549s - loss: 1.3835 - - ETA: 12s - loss - ETA: 12 - ETA: 10s - loss: 1.3823 - acc:  - ETA: 9s - loss: 1.3832 - acc: 0.467 - ETA: 9s - loss: 1.383 - ETA: 8s - los - ETA: 2s - loss: 1.3866 - acc: - ETA: 2s - loss - ETA: 0s - loss: 1.3866 - \n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.16356\n",
      "Epoch 50/100\n",
      "898/897 [==============================] - 43s 48ms/step - loss: 1.3744 - acc: 0.4766 - val_loss: 1.2056 - val_acc: 0.5641\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.16356\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 51/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3476 - acc: 0.4832 - val_loss: 1.1269 - val_acc: 0.5940 - ETA:\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.16356 to 1.12690, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.51-0.59.hdf5\n",
      "Epoch 52/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3324 - acc: 0.4942 - val_loss: 1.1386 - val_acc: 0.5904\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.12690\n",
      "Epoch 53/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3259 - acc: 0.4950 - val_loss: 1.1275 - val_acc: 0.5961s - loss: 1.3249 - ac - ETA: 1s - loss: 1.3260 - acc: 0. - ETA: 1s - los\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.12690\n",
      "Epoch 54/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3255 - acc: 0.4958 - val_loss: 1.1204 - val_acc: 0.59181 - acc: 0.496\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.12690 to 1.12042, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.54-0.59.hdf5\n",
      "Epoch 55/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3237 - acc: 0.4946 - val_loss: 1.1221 - val_acc: 0.5954A: 0s - loss: 1.3231 \n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.12042\n",
      "Epoch 56/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3223 - acc: 0.4964 - val_loss: 1.1180 - val_acc: 0.5958s: 1.3224 - acc: - ETA: 0s - loss: 1.3220 - acc: \n",
      "\n",
      "Epoch 00056: val_loss improved from 1.12042 to 1.11802, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.56-0.60.hdf5\n",
      "Epoch 57/100\n",
      "898/897 [==============================] - 44s 50ms/step - loss: 1.3131 - acc: 0.4988 - val_loss: 1.1120 - val_acc: 0.5979\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.11802 to 1.11201, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.57-0.60.hdf5\n",
      "Epoch 58/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.3162 - acc: 0.4996 - val_loss: 1.1177 - val_acc: 0.6016 ETA: 4s - loss: 1.31 - ETA: 2s - loss: 1.3168 - a - ETA: 2s - loss: 1.3156  - ETA: 1s - l\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.11201\n",
      "Epoch 59/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3171 - acc: 0.5012 - val_loss: 1.1171 - val_acc: 0.5993\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.11201\n",
      "Epoch 60/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3131 - acc: 0.5005 - val_loss: 1.1037 - val_acc: 0.6039 4s - loss: 1.3107 - acc - ETA: 4s - loss: 1.3118 - a - ETA: 3s - loss: 1.3133 -\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.11201 to 1.10365, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.60-0.60.hdf5\n",
      "Epoch 61/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3148 - acc: 0.4973 - val_loss: 1.1193 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.10365\n",
      "Epoch 62/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3139 - acc: 0.4986 - val_loss: 1.1145 - val_acc: 0.6011 - loss: 1.316 - ETA: 5s - loss: 1.3136 - acc: - ETA: 5s - loss: 1.31 - ETA: 4s - l\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.10365\n",
      "Epoch 63/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3076 - acc: 0.5038 - val_loss: 1.1123 - val_acc: 0.6013ss\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.10365\n",
      "Epoch 64/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3086 - acc: 0.5029 - val_loss: 1.1182 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.10365\n",
      "Epoch 65/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3096 - acc: 0.5020 - val_loss: 1.1039 - val_acc: 0.5977 6s - loss: 1.3095 - acc:  - ETA: 6s - loss: 1.3087 - - ETA: 5s - loss:  - ETA: 4s -\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.10365\n",
      "Epoch 66/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3066 - acc: 0.5031 - val_loss: 1.1101 - val_acc: 0.60819s - loss: 1.3031 - acc:  - ETA: 9s - loss: 1 - ETA: 7s - loss: 1.3053 - acc - ETA: 7s - loss: 1 - ETA: 6s - loss: 1.3060 - acc: 0.504 - ETA: 6s - loss: 1.3\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.10365\n",
      "Epoch 67/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3090 - acc: 0.4999 - val_loss: 1.1162 - val_acc: 0.6003 0s - loss: 1.3086 - acc:\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.10365\n",
      "Epoch 68/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3034 - acc: 0.5056 - val_loss: 1.1163 - val_acc: 0.60593060 - ac - ETA: 0s - loss: 1.3052 \n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.10365\n",
      "Epoch 69/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.3078 - acc: 0.5003 - val_loss: 1.1106 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.10365\n",
      "Epoch 70/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3039 - acc: 0.5029 - val_loss: 1.1134 - val_acc: 0.6010- loss: 1.3087 - - ETA: 15s - loss: 1.3078 - acc: 0.50 - ETA: 15s - ETA: 2s - loss: - ETA: 1s - loss:\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.10365\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 46s 51ms/step - loss: 1.3069 - acc: 0.5019 - val_loss: 1.1094 - val_acc: 0.60731.3075 - acc: 0.5\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.10365\n",
      "Epoch 72/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.3041 - acc: 0.5024 - val_loss: 1.1033 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.10365 to 1.10329, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.72-0.60.hdf5\n",
      "Epoch 73/100\n",
      "898/897 [==============================] - 47s 52ms/step - loss: 1.3008 - acc: 0.5054 - val_loss: 1.1072 - val_acc: 0.6042s - loss: 1.3012 - \n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.10329\n",
      "Epoch 74/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.3105 - acc: 0.4984 - val_loss: 1.0981 - val_acc: 0.6004TA: 0s - loss: 1.3096 - acc\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.10329 to 1.09809, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.74-0.60.hdf5\n",
      "Epoch 75/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.2971 - acc: 0.5046 - val_loss: 1.1165 - val_acc: 0.6010- loss: 1.2984 -  - ETA: 8 - ETA: 6s - lo - ETA:  - ETA: 2s - loss: 1.2973 - ac - ETA: 2s - loss: 1.2977 -  - ETA: 1s - l\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.09809\n",
      "Epoch 76/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.3002 - acc: 0.5040 - val_loss: 1.1007 - val_acc: 0.5958\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.09809\n",
      "Epoch 77/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.2956 - acc: 0.5061 - val_loss: 1.1053 - val_acc: 0.5997A: 7s - loss: 1.29 - ETA: 6s - loss: 1.2964  - ETA: 5s - loss: 1.2947 - acc - ETA: 4s - lo - ETA: 0s - loss: 1.2963 - a\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.09809\n",
      "Epoch 78/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.3027 - acc: 0.5001 - val_loss: 1.1091 - val_acc: 0.6006- ETA: 2 - ETA: 0s - loss: 1.3026 - acc: 0.5\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.09809\n",
      "Epoch 79/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3019 - acc: 0.5032 - val_loss: 1.1024 - val_acc: 0.6056\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.09809\n",
      "Epoch 80/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2990 - acc: 0.5046 - val_loss: 1.0996 - val_acc: 0.6021 1s - loss: 1\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.09809\n",
      "Epoch 81/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3020 - acc: 0.5028 - val_loss: 1.0955 - val_acc: 0.6067s - loss: 1.2960 - a - ETA: 11s - loss: 1. - - ETA: 9s - loss: 1\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.09809 to 1.09547, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.81-0.61.hdf5\n",
      "Epoch 82/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2998 - acc: 0.5043 - val_loss: 1.1060 - val_acc: 0.6014\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.09547\n",
      "Epoch 83/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2970 - acc: 0.5041 - val_loss: 1.0980 - val_acc: 0.6006 loss: 1.2938 - \n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.09547\n",
      "Epoch 84/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2947 - acc: 0.5051 - val_loss: 1.1048 - val_acc: 0.6030.2980  - ETA: 2s - loss: 1.2973 - acc: - ETA: 1s - loss: 1.2969  - ETA: 0s - loss: 1.2961\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.09547\n",
      "Epoch 85/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2969 - acc: 0.5026 - val_loss: 1.1017 - val_acc: 0.60596s - loss: 1.3007 - acc: 0.49 - ETA: 6s - loss: 1.3003 - acc:  - - ET - ETA: 1s - loss: 1.2979 - acc: - ETA: 1s - loss: 1.2984 - acc: 0 - ETA: 0s - loss: 1.298\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.09547\n",
      "Epoch 86/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3019 - acc: 0.5039 - val_loss: 1.0923 - val_acc: 0.6053TA: 3s - loss:  - ETA: 1s\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.09547 to 1.09230, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.86-0.61.hdf5\n",
      "Epoch 87/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2990 - acc: 0.5058 - val_loss: 1.1003 - val_acc: 0.6048\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.09230\n",
      "Epoch 88/100\n",
      "898/897 [==============================] - 46s 51ms/step - loss: 1.2872 - acc: 0.5107 - val_loss: 1.1011 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.09230\n",
      "Epoch 89/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2940 - acc: 0.5064 - val_loss: 1.1065 - val_acc: 0.6009 loss: 1.2950 - acc: - ETA: 1s - loss: 1.2943 - acc:  - ETA: 1s - loss: 1.2954 - acc: 0.5 - ETA: 1s - loss: 1.\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.09230\n",
      "Epoch 90/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2929 - acc: 0.5039 - val_loss: 1.1073 - val_acc: 0.5984 a - ETA: 8s - loss: 1.2873 - a - ETA: 7s - loss: - ETA: 3s - ETA: 1s \n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.09230\n",
      "Epoch 91/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.3021 - acc: 0.5035 - val_loss: 1.0969 - val_acc: 0.60502s - loss: 1.2982 - acc: 0.50 -\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.09230\n",
      "Epoch 92/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2904 - acc: 0.5106 - val_loss: 1.0968 - val_acc: 0.6048\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.09230\n",
      "Epoch 93/100\n",
      "898/897 [==============================] - 44s 50ms/step - loss: 1.2975 - acc: 0.5044 - val_loss: 1.0983 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.09230\n",
      "Epoch 94/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2901 - acc: 0.5065 - val_loss: 1.0942 - val_acc: 0.6060 1.2 - ETA: 0s - loss: 1.2898 - acc: 0.\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.09230\n",
      "Epoch 95/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2896 - acc: 0.5072 - val_loss: 1.0997 - val_acc: 0.6050: 1.28 - ETA: 2s - loss: 1.2893 - acc: 0.50 - ETA: 1s - loss: 1.289 - ETA: 1s - loss: 1.2907 - acc: 0.50 - ETA: 0s - loss: 1.2907\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.09230\n",
      "Epoch 96/100\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.2899 - acc: 0.5075 - val_loss: 1.1097 - val_acc: 0.6027ac - ETA: 6s - loss: 1.2882 - ac - ETA: 5s - loss: 1.2879 - acc:  - ETA: 2s - loss: 1.2888 - acc: 0. - ETA: 2s - loss: 1.2894 - acc: 0.507 - ETA: 2s - loss: 1.2895 - acc - ET\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.09230\n",
      "Epoch 97/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2882 - acc: 0.5088 - val_loss: 1.1002 - val_acc: 0.6037\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.09230\n",
      "Epoch 98/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2937 - acc: 0.5106 - val_loss: 1.0946 - val_acc: 0.6056971 - a - ETA: 5s - l - ETA: 3s  - ETA: 1s - loss: 1. - ETA: 0s - loss: 1.2947 - acc: \n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.09230\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 99/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2903 - acc: 0.5091 - val_loss: 1.0941 - val_acc: 0.6039.2881\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.09230\n",
      "Epoch 100/100\n",
      "898/897 [==============================] - 44s 49ms/step - loss: 1.2861 - acc: 0.5098 - val_loss: 1.0952 - val_acc: 0.60502855 - ETA: 1s - loss: 1.2860 -  - ETA: 0s - loss: 1.2857 - acc: 0.51 - ETA: 0s - loss: 1.2858 - acc: 0.51 - ETA: 0s - loss: 1.2857 - acc:\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.09230\n"
     ]
    }
   ],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(train_faces) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 62, 62, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 62, 62, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 62, 62, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 60, 8)    576         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 60, 60, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 60, 60, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 60, 60, 16)   200         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 60, 60, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 60, 60, 16)   400         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 16)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 30, 30, 32)   656         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 30, 30, 32)   1312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 32)   512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 15, 15, 64)   2336        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 15, 15, 64)   4672        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 8, 8, 128)    8768        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 8, 8, 128)    17536       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 128)    8192        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 128)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 7)      8071        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '../trained_models/emotion_models/'\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=5,\n",
    "                        width_shift_range=0.05,\n",
    "                        height_shift_range=0.05,\n",
    "                        zoom_range=.05,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: fer2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeb3\\AI project\\face_classification-master\\src\\utils\\datasets.py:71: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  emotions = pd.get_dummies(data['emotion']).as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "898/897 [==============================] - 39s 43ms/step - loss: 1.6926 - acc: 0.3641 - val_loss: 1.6366 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.63662, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.01-0.42.hdf5\n",
      "Epoch 2/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.4167 - acc: 0.4725 - val_loss: 1.4580 - val_acc: 0.4657\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63662 to 1.45804, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.02-0.47.hdf5\n",
      "Epoch 3/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.3163 - acc: 0.5102 - val_loss: 1.2959 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.45804 to 1.29594, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.03-0.52.hdf5\n",
      "Epoch 4/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.2604 - acc: 0.5286 - val_loss: 1.4019 - val_acc: 0.4833\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.29594\n",
      "Epoch 5/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.2196 - acc: 0.5477 - val_loss: 1.2197 - val_acc: 0.5439\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.29594 to 1.21968, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.05-0.54.hdf5\n",
      "Epoch 6/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.1811 - acc: 0.5600 - val_loss: 1.2411 - val_acc: 0.5517\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.21968\n",
      "Epoch 7/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.1513 - acc: 0.5700 - val_loss: 1.2166 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.21968 to 1.21655, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.07-0.55.hdf5\n",
      "Epoch 8/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.1285 - acc: 0.5809 - val_loss: 1.1824 - val_acc: 0.5649\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.21655 to 1.18237, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.08-0.56.hdf5\n",
      "Epoch 9/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.1101 - acc: 0.5866 - val_loss: 1.2504 - val_acc: 0.5535\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.18237\n",
      "Epoch 10/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.0918 - acc: 0.5951 - val_loss: 1.1815 - val_acc: 0.5603\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.18237 to 1.18148, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.10-0.56.hdf5\n",
      "Epoch 11/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0821 - acc: 0.5996 - val_loss: 1.2884 - val_acc: 0.5541\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.18148\n",
      "Epoch 12/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0636 - acc: 0.6053 - val_loss: 1.2074 - val_acc: 0.5628\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.18148\n",
      "Epoch 13/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0524 - acc: 0.6101 - val_loss: 1.2244 - val_acc: 0.5504\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.18148\n",
      "Epoch 14/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0409 - acc: 0.6144 - val_loss: 1.0831 - val_acc: 0.5979\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.18148 to 1.08305, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.14-0.60.hdf5\n",
      "Epoch 15/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0311 - acc: 0.6153 - val_loss: 1.1954 - val_acc: 0.5628\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.08305\n",
      "Epoch 16/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0209 - acc: 0.6212 - val_loss: 1.1320 - val_acc: 0.5862\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.08305\n",
      "Epoch 17/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 1.0131 - acc: 0.6240 - val_loss: 1.1425 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.08305\n",
      "Epoch 18/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 1.0022 - acc: 0.6290 - val_loss: 1.0821 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.08305 to 1.08210, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.18-0.60.hdf5\n",
      "Epoch 19/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9967 - acc: 0.6292 - val_loss: 1.1188 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.08210\n",
      "Epoch 20/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9866 - acc: 0.6299 - val_loss: 1.1317 - val_acc: 0.5805\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.08210\n",
      "Epoch 21/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9806 - acc: 0.6370 - val_loss: 1.0917 - val_acc: 0.5964\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.08210\n",
      "Epoch 22/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9759 - acc: 0.6330 - val_loss: 1.1100 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.08210\n",
      "Epoch 23/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9668 - acc: 0.6404 - val_loss: 1.1181 - val_acc: 0.5940\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.08210\n",
      "Epoch 24/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9588 - acc: 0.6465 - val_loss: 1.0912 - val_acc: 0.6066\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.08210\n",
      "Epoch 25/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9521 - acc: 0.6462 - val_loss: 1.0513 - val_acc: 0.6234\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.08210 to 1.05131, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.25-0.62.hdf5\n",
      "Epoch 26/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.9468 - acc: 0.6478 - val_loss: 1.0553 - val_acc: 0.6098\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.05131\n",
      "Epoch 27/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9402 - acc: 0.6491 - val_loss: 1.0995 - val_acc: 0.6025\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.05131\n",
      "Epoch 28/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9362 - acc: 0.6512 - val_loss: 1.0620 - val_acc: 0.6177\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.05131\n",
      "Epoch 29/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9284 - acc: 0.6585 - val_loss: 1.0715 - val_acc: 0.6066\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.05131\n",
      "Epoch 30/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.9239 - acc: 0.6567 - val_loss: 1.0619 - val_acc: 0.6043\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.05131\n",
      "Epoch 31/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.9226 - acc: 0.6574 - val_loss: 1.0314 - val_acc: 0.6303\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.05131 to 1.03139, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.31-0.63.hdf5\n",
      "Epoch 32/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.9138 - acc: 0.6593 - val_loss: 1.0594 - val_acc: 0.6166\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.03139\n",
      "Epoch 33/100\n",
      "898/897 [==============================] - 33s 36ms/step - loss: 0.9087 - acc: 0.6627 - val_loss: 1.0595 - val_acc: 0.6159\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.03139\n",
      "Epoch 34/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.9039 - acc: 0.6643 - val_loss: 1.0556 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.03139\n",
      "Epoch 35/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.9070 - acc: 0.6628 - val_loss: 1.1126 - val_acc: 0.6096\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.03139\n",
      "Epoch 36/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8971 - acc: 0.6691 - val_loss: 1.0280 - val_acc: 0.6286\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.03139 to 1.02800, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.36-0.63.hdf5\n",
      "Epoch 37/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8920 - acc: 0.6695 - val_loss: 1.0859 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.02800\n",
      "Epoch 38/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.8882 - acc: 0.6733 - val_loss: 1.0591 - val_acc: 0.6148\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.02800\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8916 - acc: 0.6698 - val_loss: 1.0269 - val_acc: 0.6262\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.02800 to 1.02685, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.39-0.63.hdf5\n",
      "Epoch 40/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8841 - acc: 0.6765 - val_loss: 1.0198 - val_acc: 0.6293ss: - ETA: 1s - \n",
      "\n",
      "Epoch 00040: val_loss improved from 1.02685 to 1.01981, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.40-0.63.hdf5\n",
      "Epoch 41/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8789 - acc: 0.6747 - val_loss: 1.0713 - val_acc: 0.6137\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.01981\n",
      "Epoch 42/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8734 - acc: 0.6762 - val_loss: 1.0843 - val_acc: 0.6014\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.01981\n",
      "Epoch 43/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8741 - acc: 0.6762 - val_loss: 1.0204 - val_acc: 0.6323\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.01981\n",
      "Epoch 44/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8683 - acc: 0.6815 - val_loss: 1.0384 - val_acc: 0.6233\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.01981\n",
      "Epoch 45/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8671 - acc: 0.6788 - val_loss: 1.0412 - val_acc: 0.6262\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.01981\n",
      "Epoch 46/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8615 - acc: 0.6815 - val_loss: 1.0596 - val_acc: 0.6116\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.01981\n",
      "Epoch 47/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8576 - acc: 0.6820 - val_loss: 1.0584 - val_acc: 0.6187\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.01981\n",
      "Epoch 48/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.8558 - acc: 0.6830 - val_loss: 1.0791 - val_acc: 0.6237\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.01981\n",
      "Epoch 49/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8559 - acc: 0.6801 - val_loss: 1.0608 - val_acc: 0.6197\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.01981\n",
      "Epoch 50/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8486 - acc: 0.6880 - val_loss: 1.0258 - val_acc: 0.6404\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.01981\n",
      "Epoch 51/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8503 - acc: 0.6851 - val_loss: 1.0648 - val_acc: 0.6236\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.01981\n",
      "Epoch 52/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.8452 - acc: 0.6854 - val_loss: 1.0617 - val_acc: 0.6241\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.01981\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 53/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7838 - acc: 0.7146 - val_loss: 0.9846 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.01981 to 0.98465, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.53-0.65.hdf5\n",
      "Epoch 54/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7756 - acc: 0.7132 - val_loss: 0.9771 - val_acc: 0.6538\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.98465 to 0.97707, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.54-0.65.hdf5\n",
      "Epoch 55/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7599 - acc: 0.7225 - val_loss: 0.9749 - val_acc: 0.6541\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.97707 to 0.97491, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.55-0.65.hdf5\n",
      "Epoch 56/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7535 - acc: 0.7255 - val_loss: 0.9808 - val_acc: 0.6542\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.97491\n",
      "Epoch 57/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.7538 - acc: 0.7231 - val_loss: 0.9844 - val_acc: 0.6513\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.97491\n",
      "Epoch 58/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7492 - acc: 0.7282 - val_loss: 0.9804 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.97491\n",
      "Epoch 59/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7440 - acc: 0.7292 - val_loss: 0.9842 - val_acc: 0.6513\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.97491\n",
      "Epoch 60/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7382 - acc: 0.7309 - val_loss: 0.9860 - val_acc: 0.6548\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.97491\n",
      "Epoch 61/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7395 - acc: 0.7276 - val_loss: 0.9833 - val_acc: 0.6546\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.97491\n",
      "Epoch 62/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.7363 - acc: 0.7318 - val_loss: 0.9798 - val_acc: 0.6552\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.97491\n",
      "Epoch 63/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7353 - acc: 0.7313 - val_loss: 0.9841 - val_acc: 0.6565\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.97491\n",
      "Epoch 64/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7359 - acc: 0.7320 - val_loss: 0.9901 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.97491\n",
      "Epoch 65/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7297 - acc: 0.7315 - val_loss: 0.9954 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.97491\n",
      "Epoch 66/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7335 - acc: 0.7320 - val_loss: 0.9878 - val_acc: 0.6560\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.97491\n",
      "Epoch 67/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7298 - acc: 0.7315 - val_loss: 0.9898 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.97491\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 68/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7232 - acc: 0.7333 - val_loss: 0.9875 - val_acc: 0.6597\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.97491\n",
      "Epoch 69/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7225 - acc: 0.7394 - val_loss: 0.9881 - val_acc: 0.6583\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.97491\n",
      "Epoch 70/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7174 - acc: 0.7397 - val_loss: 0.9874 - val_acc: 0.6601\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.97491\n",
      "Epoch 71/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7183 - acc: 0.7369 - val_loss: 0.9886 - val_acc: 0.6597\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.97491\n",
      "Epoch 72/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7193 - acc: 0.7365 - val_loss: 0.9870 - val_acc: 0.6588\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.97491\n",
      "Epoch 73/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7220 - acc: 0.7338 - val_loss: 0.9881 - val_acc: 0.6585\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.97491\n",
      "Epoch 74/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.7141 - acc: 0.7411 - val_loss: 0.9880 - val_acc: 0.6598\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.97491\n",
      "Epoch 75/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7176 - acc: 0.7352 - val_loss: 0.9876 - val_acc: 0.6581\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.97491\n",
      "Epoch 76/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7175 - acc: 0.7381 - val_loss: 0.9888 - val_acc: 0.6585\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.97491\n",
      "Epoch 77/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7194 - acc: 0.7374 - val_loss: 0.9884 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.97491\n",
      "Epoch 78/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7142 - acc: 0.7393 - val_loss: 0.9877 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.97491\n",
      "Epoch 79/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7151 - acc: 0.7372 - val_loss: 0.9892 - val_acc: 0.6581\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.97491\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 80/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.7186 - acc: 0.7353 - val_loss: 0.9901 - val_acc: 0.6576\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.97491\n",
      "Epoch 81/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7141 - acc: 0.7404 - val_loss: 0.9888 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.97491\n",
      "Epoch 82/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7151 - acc: 0.7413 - val_loss: 0.9886 - val_acc: 0.6583\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.97491\n",
      "Epoch 83/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7167 - acc: 0.7389 - val_loss: 0.9888 - val_acc: 0.6576\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.97491\n",
      "Epoch 84/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7163 - acc: 0.7399 - val_loss: 0.9892 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.97491\n",
      "Epoch 85/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7146 - acc: 0.7392 - val_loss: 0.9898 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.97491\n",
      "Epoch 86/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7162 - acc: 0.7389 - val_loss: 0.9890 - val_acc: 0.6580\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.97491\n",
      "Epoch 87/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7149 - acc: 0.7379 - val_loss: 0.9882 - val_acc: 0.6580\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.97491\n",
      "Epoch 88/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7174 - acc: 0.7395 - val_loss: 0.9880 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.97491\n",
      "Epoch 89/100\n",
      "898/897 [==============================] - 33s 37ms/step - loss: 0.7165 - acc: 0.7366 - val_loss: 0.9896 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.97491\n",
      "Epoch 90/100\n",
      "898/897 [==============================] - 34s 37ms/step - loss: 0.7143 - acc: 0.7386 - val_loss: 0.9883 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.97491\n",
      "Epoch 91/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7183 - acc: 0.7340 - val_loss: 0.9889 - val_acc: 0.6578\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.97491\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 92/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7110 - acc: 0.7422 - val_loss: 0.9887 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.97491\n",
      "Epoch 93/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7146 - acc: 0.7410 - val_loss: 0.9899 - val_acc: 0.6581\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.97491\n",
      "Epoch 94/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7152 - acc: 0.7405 - val_loss: 0.9883 - val_acc: 0.6583\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.97491\n",
      "Epoch 95/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7194 - acc: 0.7384 - val_loss: 0.9896 - val_acc: 0.6588\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.97491\n",
      "Epoch 96/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7177 - acc: 0.7388 - val_loss: 0.9897 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.97491\n",
      "Epoch 97/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7148 - acc: 0.7422 - val_loss: 0.9893 - val_acc: 0.6580\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.97491\n",
      "Epoch 98/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7174 - acc: 0.7400 - val_loss: 0.9890 - val_acc: 0.6597\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.97491\n",
      "Epoch 99/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7145 - acc: 0.7416 - val_loss: 0.9899 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.97491\n",
      "Epoch 100/100\n",
      "898/897 [==============================] - 34s 38ms/step - loss: 0.7159 - acc: 0.7391 - val_loss: 0.9886 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.97491\n"
     ]
    }
   ],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(train_faces) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
